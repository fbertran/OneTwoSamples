[{"path":"https://fbertran.github.io/OneTwoSamples/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Frederic Bertrand. Maintainer. Ying-Ying Zhang (Robert). Author.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Frédéric Bertrand Ying-Ying Zhang (Robert) (2025). Deal One Two (Normal) Samples, R package version 1.2-0. doi:10.32614/CRAN.package.OneTwoSamples.","code":"@Manual{,   title = {Deal with One and Two (Normal) Samples},   author = {Frederic Bertrand and Ying-Ying {Zhang (Robert)}},   year = {2025},   note = {R package version 1.2-0},   url = {https://www.github.com/fbertran/OneTwoSamples},   doi = {10.32614/CRAN.package.OneTwoSamples}, }"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"onetwosamples","dir":"","previous_headings":"","what":"Deal with One and Two (Normal) Samples","title":"Deal with One and Two (Normal) Samples","text":"https://doi.org/10.32614/CRAN.package.OneTwoSamples goal OneTwoSamples introduce R function one_two_sample() can deal one two (normal) samples, Ying-Ying Zhang, Yi Wei (2012) doi:10.2991/asshm-13.2013.29. one normal sample x, function reports descriptive statistics, plot, interval estimation test hypothesis x. two normal samples x y, function reports descriptive statistics, plot, interval estimation test hypothesis x y, respectively. also reports interval estimation test hypothesis mu1-mu2 (difference means x y) sigma1^2 / sigma2^2 (ratio variances x y), tests whether x y population, finds correlation coefficient x y x y length.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Deal with One and Two (Normal) Samples","text":"can install released version OneTwoSamples CRAN : can install development version OneTwoSamples github :","code":"install.packages(\"OneTwoSamples\") devtools::install_github(\"fbertran/OneTwoSamples\")"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Deal with One and Two (Normal) Samples","text":"basic example shows solve common problem:","code":"library(OneTwoSamples)"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"one-sample","dir":"","previous_headings":"","what":"One sample","title":"Deal with One and Two (Normal) Samples","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.0796212 0.8775947 1.0682239 0.7741274 1.2866047 1.3960800 0.9265557 0.7911731 #>  [9] 1.1139439 0.9729891"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"one_samplex---one_two_samplex-","dir":"","previous_headings":"","what":"one_sample(x, …) == one_two_sample(x, …)","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_sample(x, mu = 1, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.028691 10 0.9246617 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 1     H1: mu > 1  #>       mean df         Z   p_value #> 1 1.028691 10 0.4536504 0.3250402 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.03787327 10 0.02068782 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.03787327 10 9.468318 0.4883082 one_two_sample(x, mu = 1, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.028691 10 0.9246617 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 1     H1: mu > 1  #>       mean df         Z   p_value #> 1 1.028691 10 0.4536504 0.3250402 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.03787327 10 0.02068782 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.03787327 10 9.468318 0.4883082 one_sample(x, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.028691 10 0.9246617 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 0     H1: mu > 0  #>       mean df        Z p_value #> 1 1.028691 10 16.26504       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.04116675  9 0.02189853 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.04116675  9 9.262519 0.4134029 one_two_sample(x, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.028691 10 0.9246617 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 0     H1: mu > 0  #>       mean df        Z p_value #> 1 1.028691 10 16.26504       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.04116675  9 0.02189853 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.04116675  9 9.262519 0.4134029 one_sample(x, mu = 1, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu <= 1     H1: mu > 1  #>  #>  One Sample t-test #>  #> data:  x #> t = 0.44718, df = 9, p-value = 0.3327 #> alternative hypothesis: true mean is greater than 1 #> 95 percent confidence interval: #>  0.9110764       Inf #> sample estimates: #> mean of x  #>  1.028691  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.03787327 10 0.02068782 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 1     H1: sigma2 > 1  #>          var df    chisq2   P_value #> 1 0.03787327 10 0.3787327 0.9999983 one_two_sample(x, mu = 1, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu <= 1     H1: mu > 1  #>  #>  One Sample t-test #>  #> data:  x #> t = 0.44718, df = 9, p-value = 0.3327 #> alternative hypothesis: true mean is greater than 1 #> 95 percent confidence interval: #>  0.9110764       Inf #> sample estimates: #> mean of x  #>  1.028691  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.03787327 10 0.02068782 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 1     H1: sigma2 > 1  #>          var df    chisq2   P_value #> 1 0.03787327 10 0.3787327 0.9999983 one_sample(x) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #>  One Sample t-test #>  #> data:  x #> t = 16.033, df = 9, p-value = 6.318e-08 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.8835484 1.1738344 #> sample estimates: #> mean of x  #>  1.028691  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df         a         b #> 1 0.04116675  9 0.0194767 0.1372027 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.04116675  9 0.3705008 1.665084e-05 one_two_sample(x) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.7741274 0.8898350 1.0206065 1.1053632 1.3960800  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.028691 0.04116675 0.2028959 1.020607 0.06416132 19.72369 0.3705008 10.95256 #>           R        R1  Skewness   Kurtosis #> 1 0.6219526 0.2155283 0.5482993 -0.3821252 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.94937, p-value = 0.6611 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #>  One Sample t-test #>  #> data:  x #> t = 16.033, df = 9, p-value = 6.318e-08 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.8835484 1.1738344 #> sample estimates: #> mean of x  #>  1.028691  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df         a         b #> 1 0.04116675  9 0.0194767 0.1372027 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.04116675  9 0.3705008 1.665084e-05"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"two-samples","dir":"","previous_headings":"","what":"Two samples","title":"Deal with One and Two (Normal) Samples","text":"","code":"set.seed(1) x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.8747092 1.0367287 0.8328743 1.3190562 1.0659016 0.8359063 1.0974858 1.1476649 #>  [9] 1.1151563 0.9389223 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.453534 2.116953 1.813628 1.335590 2.337479 1.986520 1.995143 2.283151 2.246366 #> [10] 2.178170 2.275693 2.234641 2.022369 1.403194 2.185948 1.983161 1.953261 1.558774 #> [19] 1.856555 2.125382 y2=rnorm(20, mean = 2, sd = 0.2); y2 #>  [1] 2.271736 1.979442 2.077534 1.989239 1.724588 1.917001 1.921142 1.988137 2.220005 #> [10] 2.152635 1.967095 1.949328 2.139393 2.111333 1.862249 1.858501 2.072916 2.153707 #> [19] 1.977531 2.176222"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"sigma1-sigma2-known-mu1-mu2-known","dir":"","previous_headings":"","what":"sigma1, sigma2 known; mu1, mu2 known","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_two_sample(x, y, sigma = c(0.2, 0.3), mu = c(1, 2)) #> Interval estimation and test of hypothesis #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 10.75516 #>           R        R1  Skewness   Kurtosis #> 1 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a      b #> 1 1.026441 10 0.9024815 1.1504 #> Test of hypothesis: mean_test1() #> H0: mu = 1     H1: mu != 1  #>       mean df         Z   p_value #> 1 1.026441 10 0.4180619 0.6759019 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02263442 10 0.01105025 0.06970931 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.04     H1: sigma2 != 0.04  #>          var df   chisq2   P_value #> 1 0.02263442 10 5.658606 0.3138319 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS      USS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 83.12008 #>          R        R1  Skewness  Kurtosis #> 1 1.117944 0.3084875 -1.003374 0.5258495 #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df        a        b #> 1 2.017276 20 1.885797 2.148754 #> Test of hypothesis: mean_test1() #> H0: mu = 2     H1: mu != 2  #>       mean df         Z   p_value #> 1 2.017276 20 0.2575318 0.7967683 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>         var df          a        b #> 1 0.0869011 20 0.05086456 0.181218 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.09     H1: sigma2 != 0.09  #>         var df   chisq2   P_value #> 1 0.0869011 20 19.31135 0.9966434 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation: interval_estimate5() #>         mean df         a          b #> 1 -0.9908352 30 -1.171535 -0.8101355 #>  #> Test of hypothesis: mean_test2() #>         mean df         Z      p_value #> 1 -0.9908352 30 -10.74712 6.114309e-27 #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation: interval_var4() #>        rate df1 df2         a         b #> 1 0.2604619  10  20 0.0939051 0.8904003 #> Test of hypothesis: var_test2() #>        rate df1 df2         F    P_value #> 1 0.2604619  10  20 0.2604619 0.03318465 #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #>  Exact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #>  Wilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"sigma1--sigma2-unknown-mu1-mu2-known","dir":"","previous_headings":"","what":"sigma1 = sigma2 unknown; mu1, mu2 known","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_two_sample(x, y2, var.equal = TRUE, mu = c(1, 2)) #> Interval estimation and test of hypothesis #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 10.75516 #>           R        R1  Skewness   Kurtosis #> 1 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 1     H1: mu != 1  #>  #>  One Sample t-test #>  #> data:  x #> t = 0.53557, df = 9, p-value = 0.6052 #> alternative hypothesis: true mean is not equal to 1 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02263442 10 0.01105025 0.06970931 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02263442 10 0.2263442 2.816068e-07 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.724588 1.942281 1.988688 2.142703 2.271736  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS     USS #> 1 20 2.025487 0.01911437 0.1382547 1.988688 0.03091469 6.825753 0.363173 82.4151 #>           R       R1   Skewness  Kurtosis #> 1 0.5471478 0.200422 -0.1631305 -0.298063 #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 2     H1: mu != 2  #>  #>  One Sample t-test #>  #> data:  y #> t = 0.82442, df = 19, p-value = 0.4199 #> alternative hypothesis: true mean is not equal to 2 #> 95 percent confidence interval: #>  1.960781 2.090192 #> sample estimates: #> mean of x  #>  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.01880822 20 0.01100874 0.03922147 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.01880822 20 0.3761644 2.573594e-14 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #>  Two Sample t-test #>  #> data:  x and y #> t = -17.884, df = 28, p-value < 2.2e-16 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.1134763 -0.8846159 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation: interval_var4() #>       rate df1 df2         a        b #> 1 1.203432  10  20 0.4338771 4.113986 #> Test of hypothesis: var_test2() #>       rate df1 df2        F   P_value #> 1 1.203432  10  20 1.203432 0.6914616 #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #>  Exact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #>  Wilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"sigma1--sigma2-unknown-mu1-mu2-known-1","dir":"","previous_headings":"","what":"sigma1 != sigma2 unknown; mu1, mu2 known","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_two_sample(x, y, mu = c(1, 2)) #> Interval estimation and test of hypothesis #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 10.75516 #>           R        R1  Skewness   Kurtosis #> 1 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 1     H1: mu != 1  #>  #>  One Sample t-test #>  #> data:  x #> t = 0.53557, df = 9, p-value = 0.6052 #> alternative hypothesis: true mean is not equal to 1 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02263442 10 0.01105025 0.06970931 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02263442 10 0.2263442 2.816068e-07 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS      USS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 83.12008 #>          R        R1  Skewness  Kurtosis #> 1 1.117944 0.3084875 -1.003374 0.5258495 #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 2     H1: mu != 2  #>  #>  One Sample t-test #>  #> data:  y #> t = 0.25589, df = 19, p-value = 0.8008 #> alternative hypothesis: true mean is not equal to 2 #> 95 percent confidence interval: #>  1.875969 2.158583 #> sample estimates: #> mean of x  #>  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>         var df          a        b #> 1 0.0869011 20 0.05086456 0.181218 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>         var df   chisq2      P_value #> 1 0.0869011 20 1.738022 6.160195e-08 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #>  Welch Two Sample t-test #>  #> data:  x and y #> t = -11.847, df = 27.907, p-value = 2.111e-12 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.162185 -0.819485 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation: interval_var4() #>        rate df1 df2         a         b #> 1 0.2604619  10  20 0.0939051 0.8904003 #> Test of hypothesis: var_test2() #>        rate df1 df2         F    P_value #> 1 0.2604619  10  20 0.2604619 0.03318465 #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #>  Exact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #>  Wilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"sigma1-sigma2-known-mu1-mu2-unknown","dir":"","previous_headings":"","what":"sigma1, sigma2 known; mu1, mu2 unknown","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_two_sample(x, y, sigma = c(0.2, 0.3)) #> Interval estimation and test of hypothesis #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 10.75516 #>           R        R1  Skewness   Kurtosis #> 1 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a      b #> 1 1.026441 10 0.9024815 1.1504 #> Test of hypothesis: mean_test1() #> H0: mu = 0     H1: mu != 0  #>       mean df        Z p_value #> 1 1.026441 10 16.22945       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02437258  9 0.01153109 0.08123021 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.04     H1: sigma2 != 0.04  #>          var df  chisq2   P_value #> 1 0.02437258  9 5.48383 0.4194824 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS      USS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 83.12008 #>          R        R1  Skewness  Kurtosis #> 1 1.117944 0.3084875 -1.003374 0.5258495 #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df        a        b #> 1 2.017276 20 1.885797 2.148754 #> Test of hypothesis: mean_test1() #> H0: mu = 0     H1: mu != 0  #>       mean df        Z p_value #> 1 2.017276 20 30.07177       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.09116068 19 0.05272238 0.1944703 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.09     H1: sigma2 != 0.09  #>          var df   chisq2   P_value #> 1 0.09116068 19 19.24503 0.8824428 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation: interval_estimate5() #>         mean df         a          b #> 1 -0.9908352 30 -1.171535 -0.8101355 #>  #> Test of hypothesis: mean_test2() #>         mean df         Z      p_value #> 1 -0.9908352 30 -10.74712 6.114309e-27 #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation and test of hypothesis: var.test() #>  #>  F test to compare two variances #>  #> data:  x and y #> F = 0.26736, num df = 9, denom df = 19, p-value = 0.04757 #> alternative hypothesis: true ratio of variances is not equal to 1 #> 95 percent confidence interval: #>  0.09283112 0.98477156 #> sample estimates: #> ratio of variances  #>          0.2673585  #>  #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #>  Exact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #>  Wilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"sigma1--sigma2-unknown-mu1-mu2-unknown","dir":"","previous_headings":"","what":"sigma1 = sigma2 unknown; mu1, mu2 unknown","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_two_sample(x, y2, var.equal = TRUE) #> Interval estimation and test of hypothesis #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 10.75516 #>           R        R1  Skewness   Kurtosis #> 1 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #>  One Sample t-test #>  #> data:  x #> t = 20.791, df = 9, p-value = 6.446e-09 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02437258  9 0.01153109 0.08123021 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02437258  9 0.2193532 1.674074e-06 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.724588 1.942281 1.988688 2.142703 2.271736  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS     USS #> 1 20 2.025487 0.01911437 0.1382547 1.988688 0.03091469 6.825753 0.363173 82.4151 #>           R       R1   Skewness  Kurtosis #> 1 0.5471478 0.200422 -0.1631305 -0.298063 #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #>  One Sample t-test #>  #> data:  y #> t = 65.519, df = 19, p-value < 2.2e-16 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  1.960781 2.090192 #> sample estimates: #> mean of x  #>  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.01911437 19 0.01105471 0.0407761 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df   chisq2      P_value #> 1 0.01911437 19 0.363173 1.369903e-13 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #>  Two Sample t-test #>  #> data:  x and y #> t = -17.884, df = 28, p-value < 2.2e-16 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.1134763 -0.8846159 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation and test of hypothesis: var.test() #>  #>  F test to compare two variances #>  #> data:  x and y #> F = 1.2751, num df = 9, denom df = 19, p-value = 0.6233 #> alternative hypothesis: true ratio of variances is not equal to 1 #> 95 percent confidence interval: #>  0.4427323 4.6965951 #> sample estimates: #> ratio of variances  #>           1.275092  #>  #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #>  Exact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #>  Wilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://fbertran.github.io/OneTwoSamples/index.html","id":"sigma1--sigma2-unknown-mu1-mu2-unknown-1","dir":"","previous_headings":"","what":"sigma1 != sigma2 unknown; mu1, mu2 unknown","title":"Deal with One and Two (Normal) Samples","text":"","code":"one_two_sample(x, y) #> Interval estimation and test of hypothesis #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS      USS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 10.75516 #>           R        R1  Skewness   Kurtosis #> 1 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #>  Shapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #>  One Sample t-test #>  #> data:  x #> t = 20.791, df = 9, p-value = 6.446e-09 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02437258  9 0.01153109 0.08123021 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02437258  9 0.2193532 1.674074e-06 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS      USS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 83.12008 #>          R        R1  Skewness  Kurtosis #> 1 1.117944 0.3084875 -1.003374 0.5258495 #>  #>  Shapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #>  One Sample t-test #>  #> data:  y #> t = 29.88, df = 19, p-value < 2.2e-16 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  1.875969 2.158583 #> sample estimates: #> mean of x  #>  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.09116068 19 0.05272238 0.1944703 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df   chisq2      P_value #> 1 0.09116068 19 1.732053 2.061657e-07 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #>  Welch Two Sample t-test #>  #> data:  x and y #> t = -11.847, df = 27.907, p-value = 2.111e-12 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.162185 -0.819485 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation and test of hypothesis: var.test() #>  #>  F test to compare two variances #>  #> data:  x and y #> F = 0.26736, num df = 9, denom df = 19, p-value = 0.04757 #> alternative hypothesis: true ratio of variances is not equal to 1 #> 95 percent confidence interval: #>  0.09283112 0.98477156 #> sample estimates: #> ratio of variances  #>          0.2673585  #>  #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #>  Exact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #>  Wilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/OneTwoSamples-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Deal with One and Two (Normal) Samples — OneTwoSamples-package","title":"Deal with One and Two (Normal) Samples — OneTwoSamples-package","text":"package, introduce R function one_two_sample() can deal one two (normal) samples, Ying-Ying Zhang, Yi Wei (2012), doi:10.2991/asshm-13.2013.29 . one normal sample x, function reports descriptive statistics, plot, interval estimation test hypothesis x. two normal samples x y, function reports descriptive statistics, plot, interval estimation test hypothesis x y, respectively. also reports interval estimation test hypothesis mu1-mu2 (difference means x y) sigma1^2/sigma2^2 (ratio variances x y), tests whether x y population, finds correlation coefficient x y x y length.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/OneTwoSamples-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deal with One and Two (Normal) Samples — OneTwoSamples-package","text":"important functions : one_two_sample() one_sample().","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/OneTwoSamples-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Deal with One and Two (Normal) Samples — OneTwoSamples-package","text":"Ying-Ying Zhang (Robert) Maintainer: Frederic Bertrand <frederic.bertrand@lecnam.net>","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/OneTwoSamples-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Deal with One and Two (Normal) Samples — OneTwoSamples-package","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/OneTwoSamples-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deal with One and Two (Normal) Samples — OneTwoSamples-package","text":"","code":"library(\"OneTwoSamples\")"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute various descriptive statistics — data_outline","title":"Compute various descriptive statistics — data_outline","text":"Compute various descriptive statistics x, mean, median, skewness, kurtosis, etc.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute various descriptive statistics — data_outline","text":"","code":"data_outline(x)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute various descriptive statistics — data_outline","text":"x numeric vector.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute various descriptive statistics — data_outline","text":"data.frame variables: N length. Mean mean. Var variance. std_dev Standard deviation. Median median. std_mean standard error sample mean. CV coefficient variation. CSS corrected sum squares. USS uncorrected sum squares. R extreme difference. R1 half extreme difference, difference upper quartile lower quartile. Skewness coefficient skewness. Kurtosis coefficient kurtosis. row.names 1.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute various descriptive statistics — data_outline","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute various descriptive statistics — data_outline","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/data_outline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute various descriptive statistics — data_outline","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.5125473 0.9988857 1.1243105 1.2296823 0.6356365 0.9505349 0.9511601 #>  [8] 0.9434589 0.8892601 1.1257964 data_outline(x) #>    N      Mean        Var   std_dev    Median   std_mean       CV       CSS #> 1 10 0.9361273 0.04821101 0.2195701 0.9508475 0.06943415 23.45515 0.4338991 #>        USS        R        R1   Skewness  Kurtosis #> 1 9.197242 0.717135 0.1901445 -0.8422809 0.3876286"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":null,"dir":"Reference","previous_headings":"","what":"Show details of an object — detail","title":"Show details of an object — detail","text":"Show details object.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show details of an object — detail","text":"","code":"detail(x)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show details of an object — detail","text":"x R object tested.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show details of an object — detail","text":"list components: x argument x. isS4 Logical, indicates whether x S4 object. isObject Logical, indicates whether x object, .e., class attribute. class class x. attributes attributes x. Usually result$attributes also list.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Show details of an object — detail","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Show details of an object — detail","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":[]},{"path":"https://fbertran.github.io/OneTwoSamples/reference/detail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show details of an object — detail","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.6738021 1.1024854 0.6273977 0.8955975 0.9894796 1.1085993 0.8171850 #>  [8] 1.0936309 1.0725903 0.7390913 t = t.test(x); t #>  #> \tOne Sample t-test #>  #> data:  x #> t = 15.376, df = 9, p-value = 9.096e-08 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.7778131 1.0461587 #> sample estimates: #> mean of x  #> 0.9119859  #>  detail(t) #> $x #>  #> \tOne Sample t-test #>  #> data:  x #> t = 15.376, df = 9, p-value = 9.096e-08 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.7778131 1.0461587 #> sample estimates: #> mean of x  #> 0.9119859  #>  #>  #> $isS4 #> [1] FALSE #>  #> $is.object #> [1] TRUE #>  #> $class #> [1] \"htest\" #>  #> $attributes #> $attributes$names #>  [1] \"statistic\"   \"parameter\"   \"p.value\"     \"conf.int\"    \"estimate\"    #>  [6] \"null.value\"  \"stderr\"      \"alternative\" \"method\"      \"data.name\"   #>  #> $attributes$class #> [1] \"htest\" #>  #>"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided interval estimation of mu of one normal sample — interval_estimate1","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"Compute two sided interval estimation mu one normal sample population variance known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"","code":"interval_estimate1(x, sigma = -1, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"x numeric vector. sigma standard deviation population. sigma>=0 indicates known, sigma<0 indicates unknown. Default unknown standard deviation. alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"data.frame variables: mean sample mean. df degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided interval estimation of mu of one normal sample — interval_estimate1","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.3777010 0.9805110 0.8128305 0.9968099 0.8346422 0.6975201 1.1870726 #>  [8] 1.0352977 1.0487371 1.3247098 interval_estimate1(x, sigma = 0.2) #>       mean df         a        b #> 1 1.029583 10 0.9056242 1.153542 interval_estimate1(x) #>       mean df         a       b #> 1 1.029583  9 0.8728165 1.18635"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"Compute two sided interval estimation mu1-mu2 two normal samples population variances known, unknown equal, unknown unequal.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"","code":"interval_estimate2(x, y, sigma = c(-1, -1), var.equal = FALSE, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"x numeric vector. y numeric vector. sigma numeric vector length 2, contains standard deviations two populations. standard deviations known, input , function computes interval endpoints using normal population; standard deviations unknown, ignore , now need consider whether two populations equal variances. See var.equal . var.equal logical variable indicating whether treat two variances equal. TRUE pooled variance used estimate variance otherwise Welch (Satterthwaite) approximation degrees freedom used. alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"data.frame variables: mean difference sample means xb-yb. df degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided interval estimation of mu1-mu2 of two normal samples — interval_estimate2","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.9732006 0.6179825 0.9441526 0.9373108 1.2134616 1.0140070 0.8721753 #>  [8] 0.9900070 0.9497033 1.0889594 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.826625 2.013959 2.173313 2.035458 1.426484 2.258626 1.927029 1.938174 #>  [9] 2.005753 2.008868 2.164948 1.317766 2.804767 1.891634 2.064007 2.322304 #> [17] 1.800474 2.334186 1.926231 1.646731  interval_estimate2(x, y, sigma = c(0.2, 0.3)) #>        mean df         a          b #> 1 -1.084271 30 -1.264971 -0.9035711 interval_estimate2(x, y, var.equal = TRUE) #>        mean df         a          b #> 1 -1.084271 28 -1.336608 -0.8319335 interval_estimate2(x, y) #>        mean       df        a          b #> 1 -1.084271 27.41274 -1.28135 -0.8871912"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"Compute two sided interval estimation mu one non-normal sample large sample size population variance known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"","code":"interval_estimate3(x, sigma = -1, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"x numeric vector. sigma standard deviation population. sigma>=0 indicates known, sigma<0 indicates unknown. Default unknown standard deviation. alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"data.frame variables: mean sample mean. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided interval estimation of mu of one non-normal sample with large sample size — interval_estimate3","text":"","code":"x = rexp(50, 1/2); x #>  [1] 0.765757945 0.308262778 0.749790982 2.834441237 0.051918341 0.374215161 #>  [7] 3.907787722 0.799317429 3.073531688 1.847652789 1.403940160 2.658441947 #> [13] 1.276329787 0.805944469 0.297973708 0.006233206 0.607387130 0.671263058 #> [19] 2.650079973 2.196284881 0.952366246 0.657141971 4.886073488 0.106721545 #> [25] 4.501601542 0.746276842 3.390559893 0.446185149 0.139539480 0.531464599 #> [31] 0.044489941 0.291552590 6.074501604 0.339542288 1.692191707 0.409996688 #> [37] 0.359350226 1.036633519 1.344301224 1.051277879 2.724453771 2.981786176 #> [43] 4.745921854 0.623930505 0.408015436 0.627983319 2.020831671 0.991458505 #> [49] 3.312639151 6.493250340 interval_estimate3(x) #>       mean        a        b #> 1 1.624372 1.171827 2.076917"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"Compute two sided one sided interval estimation mu one normal sample population variance known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"","code":"interval_estimate4(x, sigma = -1, side = 0, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"x numeric vector. sigma standard deviation population. sigma>=0 indicates known, sigma<0 indicates unknown. Default unknown standard deviation. side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1; computing one sided lower limit, input side = 1; computing two sided limits, input side = 0 (default). alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"data.frame variables: mean sample mean. df degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate4.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided interval estimation of mu of one normal sample — interval_estimate4","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.9528708 1.0088669 0.5760600 0.9343016 1.0924105 1.1387249 0.8582811 #>  [8] 0.9582206 1.0704558 1.3489427 interval_estimate4(x, sigma = 0.2, side = -1) #>        mean df    a        b #> 1 0.9939135 10 -Inf 1.097943 interval_estimate4(x, side = 1) #>        mean df         a   b #> 1 0.9939135  9 0.8776059 Inf"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"Compute two sided one sided interval estimation mu1-mu2 two normal samples population variances known, unknown equal, unknown unequal.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"","code":"interval_estimate5(x, y, sigma = c(-1, -1), var.equal = FALSE, side = 0, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"x numeric vector. y numeric vector. sigma numeric vector length 2, contains standard deviations two populations. standard deviations known, input , function computes interval endpoints using normal population; standard deviations unknown, ignore , now need consider whether two populations equal variances. See var.equal . var.equal logical variable indicating whether treat two variances equal. TRUE pooled variance used estimate variance otherwise Welch (Satterthwaite) approximation degrees freedom used. side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1; computing one sided lower limit, input side = 1; computing two sided limits, input side = 0 (default). alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"data.frame variables: mean difference sample means xb-yb. df degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_estimate5.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided interval estimation of mu1-mu2 of two normal samples — interval_estimate5","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.8441429 1.3078899 1.1400111 1.0235185 0.9432755 1.0995818 1.3219886 #>  [8] 1.3722272 1.0772498 0.7062713 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.215257 2.039573 1.440223 1.723801 2.361209 2.080180 1.459922 1.605099 #>  [9] 1.928436 1.657061 1.764657 1.751669 2.283301 1.808092 1.347131 1.934857 #> [17] 2.173974 2.587151 1.714219 1.439784  interval_estimate5(x, y, sigma = c(0.2, 0.3), side = -1) #>         mean df    a          b #> 1 -0.7821642 30 -Inf -0.6305162 interval_estimate5(x, y, var.equal = TRUE) #>         mean df         a          b #> 1 -0.7821642 28 -1.025611 -0.5387177 interval_estimate5(x, y) #>         mean       df         a          b #> 1 -0.7821642 26.24205 -0.992436 -0.5718925"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"Compute two sided interval estimation sigma^2 one normal sample population mean known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"","code":"interval_var1(x, mu = Inf, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"x numeric vector. mu population mean. known, input , function computes interval endpoints using chi-square distribution degree freedom n. unknown, ignore , function computes interval endpoints using chi-square distribution degree freedom n-1. alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"data.frame variables: var estimate population variance. population mean mu known, var = mean((x-mu)^2). mu unknown, var = var(x). df degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided interval estimation of sigma^2 of one normal sample — interval_var1","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.1584902 1.3630062 0.8126055 1.1722601 1.1243280 0.5711336 1.0969443 #>  [8] 0.9105451 1.1092194 1.2888373 interval_var1(x, mu = 1) #>         var df          a         b #> 1 0.0533823 10 0.02606153 0.1644064 interval_var1(x) #>         var df          a         b #> 1 0.0552148  9 0.02612308 0.1840228"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"Compute two sided interval estimation sigma1^2 / sigma2^2 two normal samples population means known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"","code":"interval_var2(x, y, mu = c(Inf, Inf), alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"x numeric vector. y numeric vector. mu population means. known, input , function computes interval endpoints using F distribution degree freedom (n1, n2). unknown, ignore , function computes interval endpoints using F distribution degree freedom (n1-1, n2-1). alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"data.frame variables: rate estimate ratio population variances, rate = Sx2/Sy2. population means mu known, Sx2 = 1/n1*sum((x-mu[1])^2) Sy2 = 1/n2*sum((y-mu[2])^2. mu unknown, Sx2 = var(x) Sy2 = var(y). df1 first degree freedom. df2 second degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var2","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.0337024 1.0478129 1.0472643 0.9481762 1.1298091 0.7564718 1.1683941 #>  [8] 0.6761579 1.0528332 1.0194621 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.5366596 1.7033952 2.5672710 2.3602482 1.4560367 2.1111297 1.8551970 #>  [8] 2.0303853 2.0117232 2.3194477 0.8870452 2.4800535 2.3539010 1.2048454 #> [15] 1.7675672 2.1817633 1.9099158 2.3031477 1.4691850 2.2016608 interval_var2(x, y, mu = c(1,2)) #>        rate df1 df2          a         b #> 1 0.1105592  10  20 0.03986024 0.3779515 interval_var2(x, y) #>        rate df1 df2          a         b #> 1 0.1160633   9  19 0.04029904 0.4275005"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"Compute two sided one sided interval estimation sigma^2 one normal sample population mean known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"","code":"interval_var3(x, mu = Inf, side = 0, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"x numeric vector. mu population mean. known, input , function computes interval endpoints using chi-square distribution degree freedom n. unknown, ignore , function computes interval endpoints using chi-square distribution degree freedom n-1. side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1; computing one sided lower limit, input side = 1; computing two sided limits, input side = 0 (default). alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"data.frame variables: var estimate population variance. population mean mu known, var = mean((x-mu)^2). mu unknown, var = var(x). df degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided interval estimation of sigma^2 of one normal sample — interval_var3","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.9416208 0.8444366 0.9302892 1.2023435 0.9370456 0.9989236 0.7283394 #>  [8] 1.3145855 0.7601232 0.9854689 interval_var3(x, mu = 1, side = -1) #>          var df a          b #> 1 0.03078906 10 0 0.07813888 interval_var3(x) #>          var df          a         b #> 1 0.03279536  9 0.01551605 0.1093021"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"Compute two sided one sided interval estimation sigma1^2 / sigma2^2 two normal samples population means known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"","code":"interval_var4(x, y, mu = c(Inf, Inf), side = 0, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"x numeric vector. y numeric vector. mu population means. known, input , function computes interval endpoints using F distribution degree freedom (n1, n2). unknown, ignore , function computes interval endpoints using F distribution degree freedom (n1-1, n2-1). side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1; computing one sided lower limit, input side = 1; computing two sided limits, input side = 0 (default). alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"data.frame variables: rate estimate ratio population variances, rate = Sx2/Sy2. population means mu known, Sx2 = 1/n1*sum((x-mu[1])^2) Sy2 = 1/n2*sum((y-mu[2])^2. mu unknown, Sx2 = var(x) Sy2 = var(y). df1 first degree freedom. df2 second degree freedom. confidence lower limit. b confidence upper limit.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/interval_var4.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided interval estimation of sigma1^2 / sigma2^2 of two normal samples — interval_var4","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.3168995 1.0011351 0.8703591 1.3717326 1.1656606 1.2398071 1.1200102 #>  [8] 1.0117520 0.7420473 0.9747332 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.115196 1.837262 2.066782 1.806542 1.875650 1.311562 1.810536 1.840571 #>  [9] 2.213104 1.925540 2.202581 1.821395 2.033027 2.111601 1.817043 2.313182 #> [17] 1.909188 2.425184 1.739870 1.334558 interval_var4(x, y, mu = c(1,2), side = -1) #>        rate df1 df2 a        b #> 1 0.5273226  10  20 0 1.462802 interval_var4(x, y) #>        rate df1 df2         a        b #> 1 0.5041512   9  19 0.1750493 1.856959"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"Compute two sided one sided test hypothesis mu one normal sample population variance known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"","code":"mean_test1(x, mu = 0, sigma = -1, side = 0)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"x numeric vector. mu mu mu0 null hypothesis. Default 0, .e., H0: mu = 0. sigma standard deviation population. sigma>=0 indicates known, sigma<0 indicates unknown. Default unknown standard deviation. side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: mu != mu0; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: mu < mu0; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: mu > mu0.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"data.frame variables: mean sample mean. df degree freedom. statistic statistic, sigma>=0, statistic = Z = (xb-mu)/(sigma/sqrt(n)); sigma<0, statistic = T = (xb-mu)/(sd(x)/sqrt(n)). p_value P value.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided test of hypothesis of mu of one normal sample — mean_test1","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.0753290 1.1944273 1.0517805 1.2414938 0.9461027 0.8603386 0.7023488 #>  [8] 1.4926738 1.1138596 0.7778598 mean_test1(x, mu = 1, sigma = 0.2, side = 1) #>       mean df         Z   p_value #> 1 1.045621 10 0.7213377 0.2353509 mean_test1(x, mu = 1) #>       mean df         T   p_value #> 1 1.045621  9 0.6122542 0.5555203"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"Compute two sided one sided test hypothesis mu1 mu2 two normal samples population variances known, unknown equal, unknown unequal.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"","code":"mean_test2(x, y, sigma = c(-1, -1), var.equal = FALSE, side = 0)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"x numeric vector. y numeric vector. sigma numeric vector length 2, contains standard deviations two populations. standard deviations known, input , function computes interval endpoints using normal population; standard deviations unknown, ignore , now need consider whether two populations equal variances. See var.equal . var.equal logical variable indicating whether treat two variances equal. TRUE pooled variance used estimate variance otherwise Welch (Satterthwaite) approximation degrees freedom used. side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: mu1 != mu2; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: mu1 < mu2; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: mu1 > mu2.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"data.frame variables: mean difference sample means xb-yb. df degree freedom. statistic statistic, (sigma>=0), statistic = Z; otherwise, statistic = T. p_value P value.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/mean_test2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided test of hypothesis of mu1 and mu2 of two normal samples — mean_test2","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.8694650 0.9705661 0.7451797 1.0790655 0.6134213 1.2109006 0.8358040 #>  [8] 0.8724738 0.9693751 0.7167187 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.182195 2.026518 1.528918 2.093852 2.195804 1.997613 2.518110 2.625940 #>  [9] 1.892496 1.567363 2.114383 2.027209 2.048629 2.106785 1.892086 1.967412 #> [17] 2.548336 1.411425 2.283795 2.164689 mean_test2(x, y, sigma = c(0.2, 0.3), side = 1) #>        mean df         Z p_value #> 1 -1.171381 30 -12.70541       1 mean_test2(x, y, var.equal = TRUE, side = 1) #>        mean df         T p_value #> 1 -1.171381 28 -10.86827       1 mean_test2(x, y, side = 1) #>        mean       df         T p_value #> 1 -1.171381 27.44942 -13.01289       1"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Deal with one (normal) sample — one_sample","title":"Deal with one (normal) sample — one_sample","text":"Deal one sample x, especially normal. Report descriptive statistics, plot, interval estimation test hypothesis x.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deal with one (normal) sample — one_sample","text":"","code":"one_sample(x, mu = Inf, sigma = -1, side = 0, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deal with one (normal) sample — one_sample","text":"x numeric vector. mu mu plays two roles. two sided one sided interval estimation (test hypothesis) sigma^2 one normal sample, mu population mean. known, input , function computes interval endpoints (chi-square statistic) using chi-square distribution degree freedom n. unknown, ignore (default), function computes interval endpoints (chi-square statistic) using chi-square distribution degree freedom n-1. two sided one sided test hypothesis mu one normal sample, mu mu0 null hypothesis, mu0 = (mu < Inf) mu else 0. sigma sigma plays two roles. two sided one sided interval estimation (test hypothesis) mu one normal sample, sigma standard deviation population. sigma>=0 indicates known, function computes interval endpoints (Z statistic) using standard normal distribution. sigma<0 indicates unknown, function computes interval endpoints (T statistic) using t distribution degree freedom n-1. Default unknown standard deviation. two sided one sided test hypothesis sigma^2 one normal sample, sigma sigma0 null hypothesis. Default 1, .e., H0: sigma^2 = 1. side side plays two roles used four places. two sided one sided interval estimation mu one normal sample, side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1; computing one sided lower limit, input side = 1; computing two sided limits, input side = 0 (default). two sided one sided interval estimation sigma^2 one normal sample, side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1; computing one sided lower limit, input side = 1; computing two sided limits, input side = 0 (default). two sided one sided test hypothesis mu one normal sample, side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: mu != mu0; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: mu < mu0; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: mu > mu0. two sided one sided test hypothesis sigma^2 one normal sample, side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: sigma^2 != sigma0^2; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: sigma^2 < sigma0^2; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: sigma^2 > sigma0^2. alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deal with one (normal) sample — one_sample","text":"list following components: mu_interval contains results interval estimation mu. mu_hypothesis contains results test hypothesis mu. sigma_interval contains results interval estimation sigma. sigma_hypothesis contains results test hypothesis sigma.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Deal with one (normal) sample — one_sample","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Deal with one (normal) sample — one_sample","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_sample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deal with one (normal) sample — one_sample","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.7543430 1.2079064 1.0911204 0.5240150 1.1195131 1.0255681 0.6566256 #>  [8] 1.0072219 1.2014536 1.1426218 one_sample(x, mu = 1, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.5240150 0.8175627 1.0583442 1.1368447 1.2079064  #> data_outline of x #>    N      Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 0.9730389 0.05833198 0.2415202 1.058344 0.07637538 24.82122 0.5249879 #>        USS         R        R1   Skewness   Kurtosis #> 1 9.993035 0.6838915 0.3192819 -0.9656092 -0.4767062 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.85822, p-value = 0.07271 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>        mean df         a   b #> 1 0.9730389 10 0.8690092 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 1     H1: mu > 1  #>        mean df          Z   p_value #> 1 0.9730389 10 -0.4262925 0.6650526 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.05322569 10 0.02907389 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.05322569 10 13.30642 0.2070405 one_sample(x, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.5240150 0.8175627 1.0583442 1.1368447 1.2079064  #> data_outline of x #>    N      Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 0.9730389 0.05833198 0.2415202 1.058344 0.07637538 24.82122 0.5249879 #>        USS         R        R1   Skewness   Kurtosis #> 1 9.993035 0.6838915 0.3192819 -0.9656092 -0.4767062 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.85822, p-value = 0.07271 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>        mean df         a   b #> 1 0.9730389 10 0.8690092 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 0     H1: mu > 0  #>        mean df       Z p_value #> 1 0.9730389 10 15.3851       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.05833198  9 0.03102953 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df  chisq2   P_value #> 1 0.05833198  9 13.1247 0.1570446 one_sample(x, mu = 1, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.5240150 0.8175627 1.0583442 1.1368447 1.2079064  #> data_outline of x #>    N      Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 0.9730389 0.05833198 0.2415202 1.058344 0.07637538 24.82122 0.5249879 #>        USS         R        R1   Skewness   Kurtosis #> 1 9.993035 0.6838915 0.3192819 -0.9656092 -0.4767062 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.85822, p-value = 0.07271 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu <= 1     H1: mu > 1  #>  #> \tOne Sample t-test #>  #> data:  x #> t = -0.35301, df = 9, p-value = 0.6339 #> alternative hypothesis: true mean is greater than 1 #> 95 percent confidence interval: #>  0.8330342       Inf #> sample estimates: #> mean of x  #> 0.9730389  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.05322569 10 0.02907389 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 1     H1: sigma2 > 1  #>          var df    chisq2   P_value #> 1 0.05322569 10 0.5322569 0.9999911 one_sample(x) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.5240150 0.8175627 1.0583442 1.1368447 1.2079064  #> data_outline of x #>    N      Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 0.9730389 0.05833198 0.2415202 1.058344 0.07637538 24.82122 0.5249879 #>        USS         R        R1   Skewness   Kurtosis #> 1 9.993035 0.6838915 0.3192819 -0.9656092 -0.4767062 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.85822, p-value = 0.07271 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 12.74, df = 9, p-value = 4.617e-07 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.8002658 1.1458120 #> sample estimates: #> mean of x  #> 0.9730389  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.05833198  9 0.02759787 0.1944119 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.05833198  9 0.5249879 7.503865e-05"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Deal with one and two (normal) samples — one_two_sample","title":"Deal with one and two (normal) samples — one_two_sample","text":"Deal one two (normal) samples. one normal sample x, function reports descriptive statistics, plot, interval estimation test hypothesis x. two normal samples x y, function reports descriptive statistics, plot, interval estimation test hypothesis x y, respectively. also reports interval estimation test hypothesis mu1-mu2 (difference means x y) sigma1^2/sigma2^2 (ratio variances x y), tests whether x y population, finds correlation coefficient x y x y length.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deal with one and two (normal) samples — one_two_sample","text":"","code":"one_two_sample(x, y = NULL, mu = c(Inf, Inf), sigma = c(-1, -1),                 var.equal = FALSE, ratio = 1, side = 0, alpha = 0.05)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deal with one and two (normal) samples — one_two_sample","text":"x numeric vector. y numeric vector. mu y = NULL, .e., one sample. See argument mu one_sample. two normal samples x y, mu plays one role: population means. However, mu used two places: one two sided one sided interval estimation sigma1^2 / sigma2^2 two normal samples, another two sided one sided test hypothesis sigma1^2 sigma2^2 two normal samples. mu known, input , function computes interval endpoints (F value) using F distribution degree freedom (n1, n2). unknown, ignore , function computes interval endpoints (F value) using F distribution degree freedom (n1-1, n2-1). sigma y = NULL, .e., one sample. See argument sigma one_sample. two normal samples x y, sigma plays one role: population standard deviations. However, sigma used two places: one two sided one sided interval estimation mu1-mu2 two normal samples, another two sided one sided test hypothesis mu1 mu2 two normal samples. standard deviations known, input , function computes interval endpoints using normal population; standard deviations unknown, ignore , now need consider whether two populations equal variances. See var.equal . var.equal logical variable indicating whether treat two variances equal. TRUE pooled variance used estimate variance otherwise Welch (Satterthwaite) approximation degrees freedom used. ratio hypothesized ratio population variances x y. used var.test(x, y, ratio = ratio, ...), .e., computing interval estimation test hypothesis sigma1^2 / sigma2^2 mu1 mu2 unknown. side y = NULL, .e., one sample. See argument side one_sample. two normal samples x y, sigma used four places: interval estimation mu1-mu2, test hypothesis mu1 mu2, interval estimation sigma1^2 / sigma2^2, test hypothesis sigma1^2 sigma2^2. interval estimation mu1-mu2 sigma1^2 / sigma2^2, side parameter used control whether compute two sided one sided interval estimation. computing one sided upper limit, input side = -1 (number < 0); computing one sided lower limit, input side = 1 (number > 0); computing two sided limits, input side = 0 (default). test hypothesis mu1 mu2 sigma1^2 sigma2^2, side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: mu1 != mu2 H1: sigma1^2 != sigma2^2; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: mu1 < mu2 H1: sigma1^2 < sigma2^2; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: mu1 > mu2 H1: sigma1^2 > sigma2^2. alpha significance level, real number [0, 1]. Default 0.05. 1-alpha degree confidence.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deal with one and two (normal) samples — one_two_sample","text":"list following components: one_sample_x contains results one_sample(x, ...). one_sample_y contains results one_sample(y, ...). mu1_mu2_interval contains results interval estimation mu1-mu2. mu1_mu2_hypothesis contains results test hypothesis mu1-mu2. sigma_ratio_interval contains results interval estimation sigma1^2 / sigma2^2. sigma_ratio_hypothesis contains results test hypothesis sigma1^2 / sigma2^2. res.ks contains results ks.test(x,y). res.binom contains results binom.test(sum(x<y), length(x)). res.wilcox contains results wilcox.test(x, y, ...). cor.pearson contains results cor.test(x, y, method = \"pearson\", ...). cor.kendall contains results cor.test(x, y, method = \"kendall\", ...). cor.spearman contains results cor.test(x, y, method = \"spearman\", ...).","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Deal with one and two (normal) samples — one_two_sample","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Deal with one and two (normal) samples — one_two_sample","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/one_two_sample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deal with one and two (normal) samples — one_two_sample","text":"","code":"## One sample x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.0298811 0.9227715 0.9539012 1.0784212 1.0939866 1.1977686 0.8572544 #>  [8] 1.2539380 1.1418132 1.2093845  ## one_sample(x, ...) == one_two_sample(x, ...) one_sample(x, mu = 1, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.073912 10 0.9698824 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 1     H1: mu > 1  #>       mean df        Z  p_value #> 1 1.073912 10 1.168652 0.121272 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.02118917 10 0.01157433 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.02118917 10 5.297293 0.8704546 one_two_sample(x, mu = 1, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.073912 10 0.9698824 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 1     H1: mu > 1  #>       mean df        Z  p_value #> 1 1.073912 10 1.168652 0.121272 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.02118917 10 0.01157433 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.02118917 10 5.297293 0.8704546  one_sample(x, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.073912 10 0.9698824 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 0     H1: mu > 0  #>       mean df        Z p_value #> 1 1.073912 10 16.98004       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df           a   b #> 1 0.01747354  9 0.009294995 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.01747354  9 3.931546 0.9158599 one_two_sample(x, sigma = 0.2, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a   b #> 1 1.073912 10 0.9698824 Inf #> Test of hypothesis: mean_test1() #> H0: mu <= 0     H1: mu > 0  #>       mean df        Z p_value #> 1 1.073912 10 16.98004       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df           a   b #> 1 0.01747354  9 0.009294995 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 0.04     H1: sigma2 > 0.04  #>          var df   chisq2   P_value #> 1 0.01747354  9 3.931546 0.9158599  one_sample(x, mu = 1, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu <= 1     H1: mu > 1  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 1.7682, df = 9, p-value = 0.05541 #> alternative hypothesis: true mean is greater than 1 #> 95 percent confidence interval: #>  0.9972854       Inf #> sample estimates: #> mean of x  #>  1.073912  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.02118917 10 0.01157433 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 1     H1: sigma2 > 1  #>          var df    chisq2   P_value #> 1 0.02118917 10 0.2118917 0.9999999 one_two_sample(x, mu = 1, side = 1) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu <= 1     H1: mu > 1  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 1.7682, df = 9, p-value = 0.05541 #> alternative hypothesis: true mean is greater than 1 #> 95 percent confidence interval: #>  0.9972854       Inf #> sample estimates: #> mean of x  #>  1.073912  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a   b #> 1 0.02118917 10 0.01157433 Inf #> Test of hypothesis: var_test1() #> H0: sigma2 <= 1     H1: sigma2 > 1  #>          var df    chisq2   P_value #> 1 0.02118917 10 0.2118917 0.9999999  one_sample(x) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 25.691, df = 9, p-value = 9.881e-10 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.9793508 1.1684733 #> sample estimates: #> mean of x  #>  1.073912  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df           a          b #> 1 0.01747354  9 0.008267031 0.05823672 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.01747354  9 0.1572618 3.840908e-07 one_two_sample(x) #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8572544 0.9728962 1.0862039 1.1837797 1.2539380  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.073912 0.01747354 0.1321875 1.086204 0.04180136 12.30897 0.1572618 #>        USS         R        R1   Skewness  Kurtosis #> 1 11.69013 0.3966836 0.2108836 -0.2943003 -1.065115 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.95981, p-value = 0.7837 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 25.691, df = 9, p-value = 9.881e-10 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.9793508 1.1684733 #> sample estimates: #> mean of x  #>  1.073912  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df           a          b #> 1 0.01747354  9 0.008267031 0.05823672 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.01747354  9 0.1572618 3.840908e-07  ## Two samples set.seed(1) x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 0.8747092 1.0367287 0.8328743 1.3190562 1.0659016 0.8359063 1.0974858 #>  [8] 1.1476649 1.1151563 0.9389223 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 2.453534 2.116953 1.813628 1.335590 2.337479 1.986520 1.995143 2.283151 #>  [9] 2.246366 2.178170 2.275693 2.234641 2.022369 1.403194 2.185948 1.983161 #> [17] 1.953261 1.558774 1.856555 2.125382 y2=rnorm(20, mean = 2, sd = 0.2); y2 #>  [1] 2.271736 1.979442 2.077534 1.989239 1.724588 1.917001 1.921142 1.988137 #>  [9] 2.220005 2.152635 1.967095 1.949328 2.139393 2.111333 1.862249 1.858501 #> [17] 2.072916 2.153707 1.977531 2.176222  ## sigma1, sigma2 known; mu1, mu2 known one_two_sample(x, y, sigma = c(0.2, 0.3), mu = c(1, 2)) #> Interval estimation and test of hypothesis #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 #>        USS         R        R1  Skewness   Kurtosis #> 1 10.75516 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a      b #> 1 1.026441 10 0.9024815 1.1504 #> Test of hypothesis: mean_test1() #> H0: mu = 1     H1: mu != 1  #>       mean df         Z   p_value #> 1 1.026441 10 0.4180619 0.6759019 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02263442 10 0.01105025 0.06970931 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.04     H1: sigma2 != 0.04  #>          var df   chisq2   P_value #> 1 0.02263442 10 5.658606 0.3138319 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 #>        USS        R        R1  Skewness  Kurtosis #> 1 83.12008 1.117944 0.3084875 -1.003374 0.5258495 #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df        a        b #> 1 2.017276 20 1.885797 2.148754 #> Test of hypothesis: mean_test1() #> H0: mu = 2     H1: mu != 2  #>       mean df         Z   p_value #> 1 2.017276 20 0.2575318 0.7967683 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>         var df          a        b #> 1 0.0869011 20 0.05086456 0.181218 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.09     H1: sigma2 != 0.09  #>         var df   chisq2   P_value #> 1 0.0869011 20 19.31135 0.9966434 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation: interval_estimate5() #>         mean df         a          b #> 1 -0.9908352 30 -1.171535 -0.8101355 #>  #> Test of hypothesis: mean_test2() #>         mean df         Z      p_value #> 1 -0.9908352 30 -10.74712 6.114309e-27 #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation: interval_var4() #>        rate df1 df2         a         b #> 1 0.2604619  10  20 0.0939051 0.8904003 #> Test of hypothesis: var_test2() #>        rate df1 df2         F    P_value #> 1 0.2604619  10  20 0.2604619 0.03318465 #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #> \tExact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #> \tWilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0 #>   ## sigma1 = sigma2 unknown; mu1, mu2 known one_two_sample(x, y2, var.equal = TRUE, mu = c(1, 2)) #> Interval estimation and test of hypothesis #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 #>        USS         R        R1  Skewness   Kurtosis #> 1 10.75516 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 1     H1: mu != 1  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 0.53557, df = 9, p-value = 0.6052 #> alternative hypothesis: true mean is not equal to 1 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02263442 10 0.01105025 0.06970931 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02263442 10 0.2263442 2.816068e-07 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.724588 1.942281 1.988688 2.142703 2.271736  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS #> 1 20 2.025487 0.01911437 0.1382547 1.988688 0.03091469 6.825753 0.363173 #>       USS         R       R1   Skewness  Kurtosis #> 1 82.4151 0.5471478 0.200422 -0.1631305 -0.298063 #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 2     H1: mu != 2  #>  #> \tOne Sample t-test #>  #> data:  y #> t = 0.82442, df = 19, p-value = 0.4199 #> alternative hypothesis: true mean is not equal to 2 #> 95 percent confidence interval: #>  1.960781 2.090192 #> sample estimates: #> mean of x  #>  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.01880822 20 0.01100874 0.03922147 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.01880822 20 0.3761644 2.573594e-14 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #> \tTwo Sample t-test #>  #> data:  x and y #> t = -17.884, df = 28, p-value < 2.2e-16 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.1134763 -0.8846159 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation: interval_var4() #>       rate df1 df2         a        b #> 1 1.203432  10  20 0.4338771 4.113986 #> Test of hypothesis: var_test2() #>       rate df1 df2        F   P_value #> 1 1.203432  10  20 1.203432 0.6914616 #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #> \tExact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #> \tWilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0 #>   ## sigma1 != sigma2 unknown; mu1, mu2 known one_two_sample(x, y, mu = c(1, 2)) #> Interval estimation and test of hypothesis #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 #>        USS         R        R1  Skewness   Kurtosis #> 1 10.75516 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 1     H1: mu != 1  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 0.53557, df = 9, p-value = 0.6052 #> alternative hypothesis: true mean is not equal to 1 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02263442 10 0.01105025 0.06970931 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02263442 10 0.2263442 2.816068e-07 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 #>        USS        R        R1  Skewness  Kurtosis #> 1 83.12008 1.117944 0.3084875 -1.003374 0.5258495 #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 2     H1: mu != 2  #>  #> \tOne Sample t-test #>  #> data:  y #> t = 0.25589, df = 19, p-value = 0.8008 #> alternative hypothesis: true mean is not equal to 2 #> 95 percent confidence interval: #>  1.875969 2.158583 #> sample estimates: #> mean of x  #>  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>         var df          a        b #> 1 0.0869011 20 0.05086456 0.181218 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>         var df   chisq2      P_value #> 1 0.0869011 20 1.738022 6.160195e-08 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #> \tWelch Two Sample t-test #>  #> data:  x and y #> t = -11.847, df = 27.907, p-value = 2.111e-12 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.162185 -0.819485 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation: interval_var4() #>        rate df1 df2         a         b #> 1 0.2604619  10  20 0.0939051 0.8904003 #> Test of hypothesis: var_test2() #>        rate df1 df2         F    P_value #> 1 0.2604619  10  20 0.2604619 0.03318465 #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #> \tExact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #> \tWilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0 #>   ## sigma1, sigma2 known; mu1, mu2 unknown one_two_sample(x, y, sigma = c(0.2, 0.3)) #> Interval estimation and test of hypothesis #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 #>        USS         R        R1  Skewness   Kurtosis #> 1 10.75516 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df         a      b #> 1 1.026441 10 0.9024815 1.1504 #> Test of hypothesis: mean_test1() #> H0: mu = 0     H1: mu != 0  #>       mean df        Z p_value #> 1 1.026441 10 16.22945       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02437258  9 0.01153109 0.08123021 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.04     H1: sigma2 != 0.04  #>          var df  chisq2   P_value #> 1 0.02437258  9 5.48383 0.4194824 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 #>        USS        R        R1  Skewness  Kurtosis #> 1 83.12008 1.117944 0.3084875 -1.003374 0.5258495 #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation: interval_estimate4() #>       mean df        a        b #> 1 2.017276 20 1.885797 2.148754 #> Test of hypothesis: mean_test1() #> H0: mu = 0     H1: mu != 0  #>       mean df        Z p_value #> 1 2.017276 20 30.07177       0 #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.09116068 19 0.05272238 0.1944703 #> Test of hypothesis: var_test1() #> H0: sigma2 = 0.09     H1: sigma2 != 0.09  #>          var df   chisq2   P_value #> 1 0.09116068 19 19.24503 0.8824428 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation: interval_estimate5() #>         mean df         a          b #> 1 -0.9908352 30 -1.171535 -0.8101355 #>  #> Test of hypothesis: mean_test2() #>         mean df         Z      p_value #> 1 -0.9908352 30 -10.74712 6.114309e-27 #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation and test of hypothesis: var.test() #>  #> \tF test to compare two variances #>  #> data:  x and y #> F = 0.26736, num df = 9, denom df = 19, p-value = 0.04757 #> alternative hypothesis: true ratio of variances is not equal to 1 #> 95 percent confidence interval: #>  0.09283112 0.98477156 #> sample estimates: #> ratio of variances  #>          0.2673585  #>  #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #> \tExact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #> \tWilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0 #>   ## sigma1 = sigma2 unknown; mu1, mu2 unknown one_two_sample(x, y2, var.equal = TRUE) #> Interval estimation and test of hypothesis #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 #>        USS         R        R1  Skewness   Kurtosis #> 1 10.75516 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 20.791, df = 9, p-value = 6.446e-09 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02437258  9 0.01153109 0.08123021 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02437258  9 0.2193532 1.674074e-06 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.724588 1.942281 1.988688 2.142703 2.271736  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS #> 1 20 2.025487 0.01911437 0.1382547 1.988688 0.03091469 6.825753 0.363173 #>       USS         R       R1   Skewness  Kurtosis #> 1 82.4151 0.5471478 0.200422 -0.1631305 -0.298063 #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.975, p-value = 0.8548 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  y #> t = 65.519, df = 19, p-value < 2.2e-16 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  1.960781 2.090192 #> sample estimates: #> mean of x  #>  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.01911437 19 0.01105471 0.0407761 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df   chisq2      P_value #> 1 0.01911437 19 0.363173 1.369903e-13 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #> \tTwo Sample t-test #>  #> data:  x and y #> t = -17.884, df = 28, p-value < 2.2e-16 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.1134763 -0.8846159 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.025487  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation and test of hypothesis: var.test() #>  #> \tF test to compare two variances #>  #> data:  x and y #> F = 1.2751, num df = 9, denom df = 19, p-value = 0.6233 #> alternative hypothesis: true ratio of variances is not equal to 1 #> 95 percent confidence interval: #>  0.4427323 4.6965951 #> sample estimates: #> ratio of variances  #>           1.275092  #>  #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #> \tExact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #> \tWilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0 #>   ## sigma1 != sigma2 unknown; mu1, mu2 unknown one_two_sample(x, y) #> Interval estimation and test of hypothesis #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> x and y are both from the normal populations. #>  #> x: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of x #>        0%       25%       50%       75%      100%  #> 0.8328743 0.8907625 1.0513151 1.1107387 1.3190562  #> data_outline of x #>    N     Mean        Var   std_dev   Median   std_mean       CV       CSS #> 1 10 1.026441 0.02437258 0.1561172 1.051315 0.04936859 15.20957 0.2193532 #>        USS         R        R1  Skewness   Kurtosis #> 1 10.75516 0.4861819 0.2199761 0.3512426 -0.3169031 #>  #> \tShapiro-Wilk normality test #>  #> data:  x #> W = 0.93828, p-value = 0.534 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  x #> t = 20.791, df = 9, p-value = 6.446e-09 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  0.914761 1.138120 #> sample estimates: #> mean of x  #>  1.026441  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a          b #> 1 0.02437258  9 0.01153109 0.08123021 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df    chisq2      P_value #> 1 0.02437258  9 0.2193532 1.674074e-06 #>  #> y: descriptive statistics, plot, interval estimation and test of hypothesis #> quantile of y #>       0%      25%      50%      75%     100%  #> 1.335590 1.929085 2.069661 2.237572 2.453534  #> data_outline of y #>    N     Mean        Var   std_dev   Median   std_mean       CV      CSS #> 1 20 2.017276 0.09116068 0.3019283 2.069661 0.06751321 14.96713 1.732053 #>        USS        R        R1  Skewness  Kurtosis #> 1 83.12008 1.117944 0.3084875 -1.003374 0.5258495 #>  #> \tShapiro-Wilk normality test #>  #> data:  y #> W = 0.91028, p-value = 0.06452 #>  #>  #> The data is from the normal population. #>  #> The data is from the normal population. #>  #> Interval estimation and test of hypothesis of mu #> Interval estimation and test of hypothesis: t.test() #> H0: mu = 0     H1: mu != 0  #>  #> \tOne Sample t-test #>  #> data:  y #> t = 29.88, df = 19, p-value < 2.2e-16 #> alternative hypothesis: true mean is not equal to 0 #> 95 percent confidence interval: #>  1.875969 2.158583 #> sample estimates: #> mean of x  #>  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma #> Interval estimation: interval_var3() #>          var df          a         b #> 1 0.09116068 19 0.05272238 0.1944703 #> Test of hypothesis: var_test1() #> H0: sigma2 = 1     H1: sigma2 != 1  #>          var df   chisq2      P_value #> 1 0.09116068 19 1.732053 2.061657e-07 #>  #> Interval estimation and test of hypothesis of mu1-mu2 #>  #> Interval estimation and test of hypothesis: t.test() #>  #> \tWelch Two Sample t-test #>  #> data:  x and y #> t = -11.847, df = 27.907, p-value = 2.111e-12 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.162185 -0.819485 #> sample estimates: #> mean of x mean of y  #>  1.026441  2.017276  #>  #>  #> Interval estimation and test of hypothesis of sigma1^2/sigma2^2 #> Interval estimation and test of hypothesis: var.test() #>  #> \tF test to compare two variances #>  #> data:  x and y #> F = 0.26736, num df = 9, denom df = 19, p-value = 0.04757 #> alternative hypothesis: true ratio of variances is not equal to 1 #> 95 percent confidence interval: #>  0.09283112 0.98477156 #> sample estimates: #> ratio of variances  #>          0.2673585  #>  #> n1 != n2 #>  #> Test whether x and y are from the same population #> H0: x and y are from the same population (without significant difference) #> ks.test(x,y) #>  #> \tExact two-sample Kolmogorov-Smirnov test #>  #> data:  x and y #> D = 1, p-value = 6.657e-08 #> alternative hypothesis: two-sided #>  #> wilcox.test(x, y, alternative = alternative) #>  #> \tWilcoxon rank sum exact test #>  #> data:  x and y #> W = 0, p-value = 6.657e-08 #> alternative hypothesis: true location shift is not equal to 0 #>"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the P value — p_value","title":"Compute the P value — p_value","text":"Compute P value cumulative distribution function (cdf).","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the P value — p_value","text":"","code":"p_value(cdf, x, paramet = numeric(0), side = 0)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the P value — p_value","text":"cdf cumulative distribution function. normal distribution, cdf = pnorm. x given value compute P value. paramet parameter corresponding distribution. normal distribution, paramet = c(mu, sigma). side parameter indicating whether compute one sided two sided P value. inputting side = -1 (number < 0), function computes left side P value; inputting side = 1 (number > 0), function computes right side P value; inputting side = 0 (default), function computes two sided P value.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the P value — p_value","text":"P value.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the P value — p_value","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the P value — p_value","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/p_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the P value — p_value","text":"","code":"p_value(pnorm, x = 0, side = 1) #> [1] 0.5 p_value(pt, x = 0, paramet = 5, side = 1) #> [1] 0.5"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"Compute two sided one sided test hypothesis sigma^2 one normal sample population mean known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"","code":"var_test1(x, sigma2 = 1, mu = Inf, side = 0)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"x numeric vector. sigma2 sigma2 sigma0^2 null hypothesis. Default 1, .e., H0: sigma^2 = 1. mu population mean. mu < Inf indicates known, mu == Inf indicates unknown. Default unknown population mean. side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: sigma^2 != sigma0^2; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: sigma^2 < sigma0^2; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: sigma^2 > sigma0^2.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"data.frame variables: var estimate population variance. population mean mu known, var = mean((x-mu)^2). mu unknown, var = var(x). df degree freedom. chisq2 chisquare statistic. p_value P value.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided test of hypothesis of sigma^2 of one normal sample — var_test1","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.0682239 0.7741274 1.2866047 1.3960800 0.9265557 0.7911731 1.1139439 #>  [8] 0.9729891 1.4803236 0.9921520 var_test1(x, sigma2 = 0.2^2, mu = 1, side = 1) #>          var df   chisq2 P_value #> 1 0.05881824 10 14.70456 0.14321 var_test1(x, sigma2 = 0.2^2, side = 1) #>         var df   chisq2   P_value #> 1 0.0582038  9 13.09586 0.1583167"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":null,"dir":"Reference","previous_headings":"","what":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"Compute two sided one sided test hypothesis sigma1^2 sigma2^2 two normal samples population means known unknown.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"","code":"var_test2(x, y, mu = c(Inf, Inf), side = 0)"},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"x numeric vector. y numeric vector. mu population means. known, input , function computes F value using F distribution degree freedom (n1, n2). unknown, ignore , function computes F value using F distribution degree freedom (n1-1, n2-1). side parameter used control two sided one sided test hypothesis. inputting side = 0 (default), function computes two sided test hypothesis, H1: sigma1^2 != sigma2^2; inputting side = -1 (number < 0), function computes one sided test hypothesis, H1: sigma1^2 < sigma2^2; inputting side = 1 (number > 0), function computes one sided test hypothesis, H1: sigma1^2 > sigma2^2.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"data.frame variables: rate estimate ratio population variances, rate = Sx2/Sy2. population means mu known, Sx2 = 1/n1*sum((x-mu[1])^2)              Sy2 = 1/n2*sum((y-mu[2])^2. mu unknown, Sx2 = var(x) Sy2 = var(y). df1 first degree freedom. df2 second degree freedom. F F statistic. p_value P value.","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"Zhang, Y. Y., Wei, Y. (2013), One two samples using R funtion, doi:10.2991/asshm-13.2013.29 .","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"Ying-Ying Zhang (Robert) robertzhangyying@qq.com","code":""},{"path":"https://fbertran.github.io/OneTwoSamples/reference/var_test2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two sided or one sided test of hypothesis of sigma1^2 and sigma2^2 of two normal samples — var_test2","text":"","code":"x=rnorm(10, mean = 1, sd = 0.2); x #>  [1] 1.0056004 0.8513454 1.0377585 0.6390083 1.2931110 1.0306507 1.4345223 #>  [8] 1.0951019 0.8580107 1.1221453 y=rnorm(20, mean = 2, sd = 0.3); y #>  [1] 1.719771 1.623910 2.087434 1.867012 2.000332 2.022302 1.823144 1.829399 #>  [9] 1.959446 2.353426 1.542930 2.178184 2.099885 2.318930 1.908745 2.111006 #> [17] 2.080130 1.837244 2.362360 2.348121 var_test2(x, y, mu = c(1, 2), side = 1) #>        rate df1 df2         F  P_value #> 1 0.8681847  10  20 0.8681847 0.575379 var_test2(x, y, side = 1) #>        rate df1 df2         F   P_value #> 1 0.8905436   9  19 0.8905436 0.5511375"}]
